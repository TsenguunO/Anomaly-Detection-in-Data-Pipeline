{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f307906-4ace-4ca9-a121-99ef85401ec5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Feature_engineer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# import pymysql\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m infer_signature\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mFeature_engineer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m feature_engineer_steps\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtracking\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MlflowClient\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Feature_engineer'"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay,classification_report,make_scorer, f1_score\n",
    "from sklearn.utils import resample\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn import model_selection\n",
    "from joblib import dump, load\n",
    "import mlflow.sklearn\n",
    "import mlflow\n",
    "# import pymysql\n",
    "from mlflow.models import infer_signature\n",
    "from Feature_engineer import feature_engineer_steps\n",
    "from mlflow.tracking import MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c60a05-7b45-493e-9c2b-29ad9f5598f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df = pd.read_csv(\"data/transactions_df.csv\")\n",
    "terminal_profiles_df = pd.read_csv(\"data/terminal_profiles_table.csv\")\n",
    "customer_profiles_df = pd.read_csv(\"data/customer_profiles_table.csv\")\n",
    "join_terminal = pd.merge(transactions_df, terminal_profiles_df, on='terminal_id', how='inner') #join dataset base on key value\n",
    "join_customer = pd.merge(join_terminal, customer_profiles_df, on='customer_id', how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a2133f-c081-475a-a2ac-5a78d1338727",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(join_customer.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa0a36b-b0b4-4b50-b27c-c8932c5aaddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating sample file for client demo purpose\n",
    "samle_file = transactions_df.sample(n=100, random_state=42)\n",
    "samle_file.to_csv('data/user_demo_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39fd06d-4ba1-4db9-b4e3-64e2cf10c359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineer step and one-hot enconding for categorical feature. \n",
    "# Stored in Feature_engineer.py\n",
    "train_X,train_y = feature_engineer_steps(join_customer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79688ccd-4158-4bd6-85a1-d03a428c7314",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ba96fb-8eac-4e67-9da9-b87e6bc94506",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Feature selection as part of the default pipeline\n",
    "def remove_unwanted_col(train):\n",
    "    \n",
    "    columns =  list(train.columns)\n",
    "    entries_to_remove = ['transaction_id', # remove unwanted column, and all the mostly IDs\n",
    "                         'bin_y',\n",
    "                         'mcc',\n",
    "                         'bin_x',\n",
    "                         'customer_id', \n",
    "                         'available_terminals',\n",
    "                         'terminal_id',\n",
    "                         'timestamp',                     \n",
    "                         #'lat_terminal',\n",
    "                         #'log_terminal',\n",
    "                         #'lat_customer',\n",
    "                         #'log_customer',\n",
    "                         #'mean_amount',\n",
    "                         #'mean_nb_tx_per_day',\n",
    "                         'date',\n",
    "                         'post_ts',\n",
    "                         'using_available_terminals',\n",
    "                            #'timestamp_numeric',\n",
    "                         #'per_day_difference_count',\n",
    "                         \n",
    "                         ] \n",
    "    features = [col for col in columns if col not in entries_to_remove]\n",
    "    train = train[features]\n",
    "    return train\n",
    "train_X = remove_unwanted_col(train_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4062f2-a5e7-4363-8085-cfff5f670e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_X, train_y,test_size=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16066886-cff9-4cbf-a1c5-efec855a4ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = load('../saved_model/best_model.joblib')\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred[y_pred == -1] = 0\n",
    "anomalies = X_test[y_pred == 0]\n",
    "anomalies_index = anomalies.index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e13ba1-1558-4cf2-92f1-122b94b8a8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show result in confusion matrix plot and return model metric \n",
    "def show_result(test,pred):\n",
    "        \n",
    "    cm = confusion_matrix(test, pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()\n",
    "    plt.savefig(\"confusion_matrix.png\")\n",
    "    #plt.show()\n",
    "    report = classification_report(test, pred, output_dict=True)    \n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = report['weighted avg']['recall']\n",
    "    f1_score = report['weighted avg']['f1-score']\n",
    "    return precision, recall, f1_score\n",
    "    \n",
    "def pred_baseon_threshold(model, test_data,threshold):\n",
    "    test_scores = model.decision_function(test_data)\n",
    "    num_values_below_threshold = np.sum(test_scores > threshold) # having score higher than threshold are anomalies\n",
    "    pred = test_scores\n",
    "    pred[test_scores < threshold] = 0\n",
    "    pred[test_scores != 0] = 1\n",
    "    return pred\n",
    "    \n",
    "def make_use_reject_anomalies(model, test_data, position,sensitivity,current_threshold):\n",
    "    test_scores = model.decision_function(test_data)\n",
    "    num_values_below_threshold = np.sum(test_scores > current_threshold) # having score higher than threshold are anomalies\n",
    "    pred = test_scores\n",
    "    pred[test_scores < current_threshold] = 0 #none anomalies\n",
    "\n",
    "    anomalies = pred[pred != 0] #extract anomalies\n",
    "    for index in position:\n",
    "        current_threshold += anomalies[index] * sensitivity\n",
    "    new_threshold = current_threshold\n",
    "    return new_threshold\n",
    "def export_anomaly(original_df, pred_list):\n",
    "    now = datetime.now()\n",
    "    date_time = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    label_series = pd.Series(pred_list)\n",
    "    anomalies= original_df[label_series == 1]\n",
    "    filename = f\"export_anomaly/anomaly_{date_time}.csv\"\n",
    "    anomalies.to_csv(filename, index=False)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad025a8d-20df-4658-b15a-167e58270bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = best_model.decision_function(X_train)\n",
    "train_threshold = np.percentile(train_scores, 15) #auto in scikit learn v0.22 and later has 0.5% contamination set\n",
    "y_pred = pred_baseon_threshold(best_model, X_test, train_threshold)\n",
    "adjusted_threshold = make_use_reject_anomalies(best_model, X_test, [1,3,5,6], 0.005,train_threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fe345f-4a36-45c1-9703-d6a60bbff2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, f1_socre = show_result(y_test,y_pred)\n",
    "metrics = {\"precision\": precision, \"recall\": recall, \"f1_socre\": f1_socre,\"train_threshold\":train_threshold}\n",
    "params = best_model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3b6f3d-be1b-48d8-a4b7-7a58191f5367",
   "metadata": {},
   "source": [
    "***Mlflow related code***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19a1404-ad77-4587-a4a6-74a8fb273568",
   "metadata": {},
   "outputs": [],
   "source": [
    "#listening to port\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "\n",
    "\n",
    "# Create a new MLflow Experiment\n",
    "mlflow.set_experiment(\"Isolation Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341f56f4-eb81-4c9b-a0bb-9a20f86c9c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log model into mlflow\n",
    "artifact_path = \"artifact_location\"\n",
    "\n",
    "# Initiate the MLflow run context\n",
    "with mlflow.start_run() as run:\n",
    "    # Log the parameters used for the model fit\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_artifact(local_path = \"Feature_engineer.py\")\n",
    "    mlflow.log_metrics(metrics)\n",
    "    mlflow.log_artifact(\"confusion_matrix.png\")\n",
    "    # Log an instance of the trained model for later use\n",
    "    model_info = mlflow.sklearn.log_model(sk_model=best_model, artifact_path=\"artifact_location\",input_example=X_train,signature = infer_signature(X_test, y_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
